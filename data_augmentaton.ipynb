{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  True\n",
      "/home/lucy/Documents/MachineLearning/Glacier_git\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "       label                                              tweet\n",
      "id                                                             \n",
      "1          0   @user when a father is dysfunctional and is s...\n",
      "2          0  @user @user thanks for #lyft credit i can't us...\n",
      "3          0                                bihday your majesty\n",
      "4          0  #model   i love u take with u all the time in ...\n",
      "5          0             factsguide: society now    #motivation\n",
      "...      ...                                                ...\n",
      "31958      0  ate @user isz that youuu?ðððððð...\n",
      "31959      0    to see nina turner on the airwaves trying to...\n",
      "31960      0  listening to sad songs on a monday morning otw...\n",
      "31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
      "31962      0                   thank you @user for you follow  \n",
      "\n",
      "[31962 rows x 2 columns]\n",
      "                                                   tweet\n",
      "id                                                      \n",
      "31963  #studiolife #aislife #requires #passion #dedic...\n",
      "31964   @user #white #supremacists want everyone to s...\n",
      "31965  safe ways to heal your #acne!!    #altwaystohe...\n",
      "31966  is the hp and the cursed child book up for res...\n",
      "31967    3rd #bihday to my amazing, hilarious #nephew...\n",
      "...                                                  ...\n",
      "49155  thought factory: left-right polarisation! #tru...\n",
      "49156  feeling like a mermaid ð #hairflip #neverre...\n",
      "49157  #hillary #campaigned today in #ohio((omg)) &am...\n",
      "49158  happy, at work conference: right mindset leads...\n",
      "49159  my   song \"so glad\" free download!  #shoegaze ...\n",
      "\n",
      "[17197 rows x 1 columns]\n",
      "       label                                              tweet\n",
      "5          1  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...\n",
      "9          1  \" @rhythmixx_ :hobbies include: fighting Maria...\n",
      "14         1                            \" bitch get up off me \"\n",
      "17         1                          \" bitch who do you love \"\n",
      "49         1  \" these hoes like niggas that spend money not ...\n",
      "...      ...                                                ...\n",
      "25262      1                  yo hoe will get slayed! &#128298;\n",
      "25265      1  you ain't a real nigga without goal a to chase...\n",
      "25266      1             you ain't gotta be a dyke to like hoes\n",
      "25275      1                 you got niggas, and i got bitches.\n",
      "25286      1              you niggers cheat on ya gf's? smh....\n",
      "\n",
      "[3419 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme=\"monokai\", context=\"notebook\", ticks=True, grid=True)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#train_df_dirty = pd.read_csv('/content/drive/MyDrive/Hate/DataSet/train_E6oV3lV.csv', index_col=0)\n",
    "train_df_dirty = pd.read_csv('./DataSet/train_E6oV3lV.csv', index_col=0)\n",
    "print(train_df_dirty)\n",
    "#test_df_dirty = pd.read_csv('/content/drive/MyDrive/Hate/DataSet/test_tweets_anuFYb8.csv', index_col=0)\n",
    "test_df_dirty = pd.read_csv('./DataSet/test_tweets_anuFYb8.csv', index_col=0)\n",
    "print(test_df_dirty)\n",
    "\n",
    "hate_2 = pd.read_csv('./DataSet/labeled_data.csv', index_col=0)\n",
    "hate_2 = hate_2[hate_2.hate_speech == 1][['hate_speech', 'tweet']].rename(columns={'hate_speech' : 'label'})\n",
    "print(hate_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897\n"
     ]
    }
   ],
   "source": [
    "# List of swearing words provided by the user\n",
    "swearing_words = [\n",
    "    \"alabama hot pocket\", \"alaskan pipeline\", \"anal\", \"anilingus\", \"anus\", \"apeshit\", \"arsehole\",\n",
    "    \"ass\", \"asshole\", \"assmunch\", \"auto erotic\", \"autoerotic\", \"babeland\", \"baby batter\", \"baby juice\",\n",
    "    \"ball gag\", \"ball gravy\", \"ball kicking\", \"ball licking\", \"ball sack\", \"ball sucking\", \"bangbros\",\n",
    "    \"bareback\", \"barely legal\", \"barenaked\", \"bastard\", \"bastardo\", \"bastinado\", \"bbw\", \"bdsm\", \"beaner\",\n",
    "    \"beaners\", \"beaver cleaver\", \"beaver lips\", \"bestiality\", \"big black\", \"big breasts\", \"big knockers\",\n",
    "    \"big tits\", \"bimbos\", \"birdlock\", \"bitch\", \"bitches\", \"black cock\", \"blonde action\", \"blonde on blonde action\",\n",
    "    \"blowjob\", \"blow job\", \"blow your load\", \"blue waffle\", \"blumpkin\", \"bollocks\", \"bondage\", \"boner\", \"boob\",\n",
    "    \"boobs\", \"booty call\", \"brown showers\", \"brunette action\", \"bukkake\", \"bulldyke\", \"bullet vibe\", \"bullshit\",\n",
    "    \"bung hole\", \"bunghole\", \"busty\", \"butt\", \"buttcheeks\", \"butthole\", \"camel toe\", \"camgirl\", \"camslut\", \"camwhore\",\n",
    "    \"carpet muncher\", \"carpetmuncher\", \"chocolate rosebuds\", \"circlejerk\", \"cleveland steamer\", \"clit\", \"clitoris\",\n",
    "    \"clover clamps\", \"clusterfuck\", \"cock\", \"cocks\", \"coprolagnia\", \"coprophilia\", \"cornhole\", \"coon\", \"coons\",\n",
    "    \"creampie\", \"cum\", \"cumming\", \"cunnilingus\", \"cunt\", \"darkie\", \"date rape\", \"daterape\", \"deep throat\", \"deepthroat\",\n",
    "    \"dendrophilia\", \"dick\", \"dildo\", \"dingleberry\", \"dingleberries\", \"dirty pillows\", \"dirty sanchez\", \"doggie style\",\n",
    "    \"doggiestyle\", \"doggy style\", \"doggystyle\", \"dog style\", \"dolcett\", \"domination\", \"dominatrix\", \"dommes\", \"donkey punch\",\n",
    "    \"double dong\", \"double penetration\", \"dp action\", \"dry hump\", \"dvda\", \"eat my ass\", \"ecchi\", \"ejaculation\", \"erotic\",\n",
    "    \"erotism\", \"escort\", \"eunuch\", \"faggot\", \"fecal\", \"felch\", \"fellatio\", \"feltch\", \"female squirting\", \"femdom\", \"figging\",\n",
    "    \"fingerbang\", \"fingering\", \"fisting\", \"foot fetish\", \"footjob\", \"frotting\", \"fuck\", \"fuck buttons\", \"fuckin\", \"fucking\",\n",
    "    \"fucktards\", \"fudge packer\", \"fudgepacker\", \"futanari\", \"gang bang\", \"gay sex\", \"genitals\", \"giant cock\", \"girl on\",\n",
    "    \"girl on top\", \"girls gone wild\", \"goatcx\", \"goatse\", \"god damn\", \"gokkun\", \"golden shower\", \"goodpoop\", \"goo girl\",\n",
    "    \"goregasm\", \"grope\", \"group sex\", \"g-spot\", \"guro\", \"hand job\", \"handjob\", \"hard core\", \"hardcore\", \"hentai\", \"homoerotic\",\n",
    "    \"honkey\", \"hooker\", \"hot carl\", \"hot chick\", \"how to kill\", \"how to murder\", \"huge fat\", \"humping\", \"incest\", \"intercourse\",\n",
    "    \"jack off\", \"jail bait\", \"jailbait\", \"jelly donut\", \"jerk off\", \"jigaboo\", \"jiggaboo\", \"jiggerboo\", \"jizz\", \"juggs\", \"kike\",\n",
    "    \"kinbaku\", \"kinkster\", \"kinky\", \"knobbing\", \"leather restraint\", \"leather straight jacket\", \"lemon party\", \"lolita\",\n",
    "    \"lovemaking\", \"make me come\", \"male squirting\", \"masturbate\", \"menage a trois\", \"milf\", \"missionary position\", \"motherfucker\",\n",
    "    \"mound of venus\", \"mr hands\", \"muff diver\", \"muffdiving\", \"nambla\", \"nawashi\", \"negro\", \"neonazi\", \"nigga\", \"nigger\", \"nig nog\",\n",
    "    \"nimphomania\", \"nipple\", \"nipples\", \"nsfw images\", \"nude\", \"nudity\", \"nympho\", \"nymphomania\", \"octopussy\", \"omorashi\", \"one cup two girls\",\n",
    "    \"one guy one jar\", \"orgasm\", \"orgy\", \"paedophile\", \"paki\", \"panties\", \"panty\", \"pedobear\", \"pedophile\", \"pegging\", \"penis\", \"phone sex\",\n",
    "    \"piece of shit\", \"pissing\", \"piss pig\", \"pisspig\", \"playboy\", \"pleasure chest\", \"pole smoker\", \"ponyplay\", \"poof\", \"poon\", \"poontang\",\n",
    "    \"punany\", \"poop chute\", \"poopchute\", \"porn\", \"porno\", \"pornography\", \"prince albert piercing\", \"pthc\", \"pubes\", \"pussy\", \"queaf\", \"queef\",\n",
    "    \"quim\", \"raghead\", \"raging boner\", \"rape\", \"raping\", \"rapist\", \"rectum\", \"reverse cowgirl\", \"rimjob\", \"rimming\", \"rosy palm\", \"rosy palm and her 5 sisters\",\n",
    "    \"rusty trombone\", \"sadism\", \"santorum\", \"scat\", \"schlong\", \"scissoring\", \"semen\", \"sex\", \"sexo\", \"sexy\", \"shaved beaver\", \"shaved pussy\", \"shemale\",\n",
    "    \"shibari\", \"shit\", \"shitblimp\", \"shitty\", \"shota\", \"shrimping\", \"skeet\", \"slanteye\", \"slut\", \"s&m\", \"smut\", \"snatch\", \"snowballing\", \"sodomize\", \"sodomy\",\n",
    "    \"spic\", \"splooge\", \"splooge moose\", \"spooge\", \"spread legs\", \"spunk\", \"strap on\", \"strapon\", \"strappado\", \"strip club\", \"style doggy\", \"suck\", \"sucks\",\n",
    "    \"suicide girls\", \"sultry women\", \"swastika\", \"swinger\", \"tainted love\", \"taste my\", \"tea bagging\", \"threesome\", \"throating\", \"tied up\", \"tight white\", \"tit\",\n",
    "    \"tits\", \"titties\", \"titty\", \"tongue in a\", \"topless\", \"tosser\", \"towelhead\", \"tranny\", \"tribadism\", \"tub girl\", \"tubgirl\", \"tushy\", \"twat\", \"twink\", \"twinkie\",\n",
    "    \"two girls one cup\", \"undressing\", \"upskirt\", \"urethra play\", \"urophilia\", \"vagina\", \"venus mound\", \"vibrator\", \"violet wand\", \"vorarephilia\", \"voyeur\",\n",
    "    \"vulva\", \"wank\", \"wetback\", \"wet dream\", \"white power\", \"wrapping men\", \"wrinkled starfish\", \"xx\", \"xxx\", \"yaoi\", \"yellow showers\", \"yiffy\", \"zoophilia\"\n",
    "]\n",
    "\n",
    "misogynistic_words = [\n",
    "    \"harpy\", \"nag\", \"scold\", \"shrew\", \"slattern\", \"siren\", \"temptress\",\n",
    "    \"termagant\", \"trollop\", \"vixen\", \"wench\", \"witch\"\n",
    "]\n",
    "\n",
    "incel_words = [\n",
    "    \"beta orbiter\", \"black pill\", \"celibate\", \"coomer\", \"gymcel\", \"looksmax\",\n",
    "    \"neet\", \"truecel\", \"volcel\", \"wagecel\"\n",
    "]\n",
    "\n",
    "race_abusive_words = [\n",
    "    \"blackamoor\", \"boong\", \"burrhead\", \"chug\", \"coolie\", \"dinge\", \"dothead\",\n",
    "    \"golliwog\", \"jig\", \"kaffir\", \"mud person\", \"mud shark\", \"moulinyan\",\n",
    "    \"mutt\", \"octoroon\", \"papoose\", \"pickaninny\", \"raghead\", \"sambo\",\n",
    "    \"skinhead\", \"snowflake\", \"spearchucker\", \"squaw\", \"tar baby\", \"whitey\"\n",
    "]\n",
    "\n",
    "transgender_abusive_words = [\n",
    "    \"cis scum\", \"gender bender\", \"gender freak\", \"it\", \"ladyboy\", \"shim\",\n",
    "    \"tg\", \"tranny\", \"trap\"\n",
    "]\n",
    "\n",
    "muslim_abusive_words = [\n",
    "    \"baghead\", \"bomber\", \"camel fucker\", \"goat lover\", \"momo\", \"muslim scum\",\n",
    "    \"raghead\", \"towelhead\"\n",
    "]\n",
    "\n",
    "sexist_abusive_words = [\n",
    "    \"broad\", \"doll\", \"honey\", \"hostess\", \"moll\", \"skirt\", \"wench\"\n",
    "]\n",
    "\n",
    "abusive_lefties = [\n",
    "    \"libtard\", \"snowflake\", \"leftard\", \"commie\", \"pinko\", \"treehugger\",\n",
    "    \"feminazi\", \"libturd\", \"leftie\", \"left-wing nutjob\"\n",
    "]\n",
    "\n",
    "trumpists_abusive = [\n",
    "    \"cuck\", \"fake news\", \"globalist\", \"liberal scum\", \"snowflake\", \"traitor\",\n",
    "    \"libtard\", \"deep state\", \"crooked Hillary\", \"nasty woman\"\n",
    "]\n",
    "\n",
    "trumpist_abusive_expressions = [\n",
    "    \"libtard\", \"snowflake\", \"leftard\", \"commie\", \"pinko\", \"socialist scum\", \"marxist loser\",\n",
    "    \"radical leftist\", \"fake news\", \"media liar\", \"mainstream media shill\", \"antifa thug\",\n",
    "    \"left-wing extremist\", \"democrat clown\", \"crooked Hillary\", \"nasty woman\", \"deep state agent\",\n",
    "    \"traitor\", \"America hater\", \"unpatriotic scum\", \"blue state loser\", \"leftist propaganda peddler\",\n",
    "    \"anarchist rioter\", \"black lives matter terrorist\", \"climate change hoaxer\", \"feminazi\",\n",
    "    \"radical feminist\", \"welfare queen\", \"open borders supporter\", \"illegal immigrant lover\",\n",
    "    \"gun grabber\", \"religious persecutor\", \"christian hater\", \"big government advocate\",\n",
    "    \"tax and spend liberal\", \"green new deal freak\", \"environmental nutjob\", \"covid hoax believer\",\n",
    "    \"mask nazi\", \"vaccine pusher\", \"cancel culture warrior\", \"identity politics fanatic\",\n",
    "    \"race baiter\", \"diversity pusher\", \"woke moron\", \"gender bender\", \"transgender agenda promoter\",\n",
    "    \"school indoctrinator\", \"CRT peddler\", \"defund the police supporter\", \"social justice warrior\",\n",
    "    \"occupy wall street radical\", \"me too movement nutcase\", \"hollywood elite\", \"celebrity hypocrite\",\n",
    "    \"china lover\", \"russia collusion liar\", \"impeachment fanatic\", \"nancy pelosi puppet\",\n",
    "    \"schumer shill\", \"progressive puppet\", \"squad member\", \"AOC fanboy\", \"bernie bro\",\n",
    "    \"leftist mob\", \"resistance member\", \"never-trumper\", \"rino\", \"establishment hack\",\n",
    "    \"globalist\", \"george soros minion\", \"deep state operative\", \"fake refugee supporter\",\n",
    "    \"traitorous diplomat\", \"election fraud conspirator\", \"unhinged protester\", \"mob rule advocate\",\n",
    "    \"portland anarchist\", \"seattle autonomous zone supporter\", \"sanctuary city lover\",\n",
    "    \"hollywood liberal\", \"silicon valley censor\", \"big tech tyrant\", \"liberal academic\",\n",
    "    \"ivy league snob\", \"antifa sympathizer\", \"progressive prosecutor\", \"defund ICE supporter\",\n",
    "    \"socialist healthcare pusher\", \"medicare for all supporter\", \"green energy nut\",\n",
    "    \"paris accord supporter\", \"Iran deal lover\", \"North Korea appeaser\", \"china appeaser\",\n",
    "    \"trade deal critic\", \"military budget cutter\", \"foreign aid lover\", \"open borders activist\",\n",
    "    \"Islamic terrorist sympathizer\", \"radical imam supporter\", \"Biden bot\", \"Kamala puppet\"\n",
    "]\n",
    "\n",
    "xenophobic_abusive_expressions = [\n",
    "    \"illegal alien\", \"invader\", \"parasite\", \"job stealer\", \"freeloader\", \"anchor baby\", \n",
    "    \"welfare leech\", \"economic migrant\", \"terrorist\", \"criminal alien\", \"refugee scum\", \n",
    "    \"border hopper\", \"drug dealer\", \"gang member\", \"disease spreader\", \"dirty foreigner\", \n",
    "    \"third-world invader\", \"illegal immigrant\", \"wetback\", \"beaner\", \"spic\", \"chink\", \n",
    "    \"gook\", \"raghead\", \"towelhead\", \"sand nigger\", \"camel jockey\", \"bomb maker\", \"jihadi\", \n",
    "    \"mujahid\", \"infidel\", \"kafir\", \"illegal worker\", \"visa overstayer\", \"undocumented\", \n",
    "    \"non-citizen\", \"outsider\", \"foreigner\", \"alien\", \"non-native\", \"intruder\", \"trespasser\", \n",
    "    \"expat\", \"transient\", \"displaced person\", \"economic refugee\", \"guest worker\", \"asylum seeker\", \n",
    "    \"naturalized citizen\", \"first-generation\", \"second-generation\", \"ethnic minority\", \n",
    "    \"newcomer\", \"settler\", \"migrant laborer\", \"foreign national\", \"stateless person\", \n",
    "    \"illegal entrant\", \"cross-border\", \"immigrant\", \"new arrival\", \"migrant\", \"visa holder\", \n",
    "    \"ethnic invader\", \"race mixer\", \"mongrel\", \"half-breed\", \"mixed blood\", \"blood traitor\", \n",
    "    \"race traitor\", \"white genocide promoter\", \"racial inferior\", \"genetic inferior\", \n",
    "    \"subhuman\", \"non-Aryan\", \"race criminal\", \"race defiler\", \"unassimilated\", \"unintegrated\", \n",
    "    \"tribalist\", \"ethnic bloc\", \"ethnic enclave\", \"foreign colony\", \"diaspora\", \"cross-cultural\", \n",
    "    \"multi-ethnic\", \"multicultural\", \"polyethnic\", \"interracial\", \"race-blind\", \"color-blind\", \n",
    "    \"diversity proponent\", \"race equalizer\", \"race leveler\", \"race integrator\", \"race harmonizer\"\n",
    "]\n",
    "\n",
    "trumpist_evangelical_abusive_expressions = [\n",
    "    \"godless liberal\", \"satanic democrat\", \"immoral atheist\", \"secular humanist\", \"anti-Christian bigot\",\n",
    "    \"leftist heathen\", \"god-hater\", \"Christ-hater\", \"Bible-basher\", \"false prophet\", \"corrupt sinner\",\n",
    "    \"liberal apostate\", \"Christ-denier\", \"abortionist\", \"baby killer\", \"pro-choice murderer\", \"anti-life scum\",\n",
    "    \"gay agenda pusher\", \"LGBTQ radical\", \"homosexual deviant\", \"transgender pervert\", \"gender confusion promoter\",\n",
    "    \"drag queen supporter\", \"family destroyer\", \"anti-family activist\", \"marriage destroyer\", \"adulterer\", \n",
    "    \"fornicator\", \"pedophile enabler\", \"child abuser\", \"godless commie\", \"communist infiltrator\", \n",
    "    \"socialist agitator\", \"religious freedom hater\", \"church attacker\", \"worship suppressor\", \n",
    "    \"biblical values hater\", \"Christian values enemy\", \"cross-burner\", \"bible-burner\", \"godless educator\", \n",
    "    \"atheist teacher\", \"indoctrinator\", \"public school atheist\", \"university atheist\", \"godless professor\", \n",
    "    \"secular scientist\", \"evolution pusher\", \"climate change fanatic\", \"tree hugger\", \"eco-freak\", \n",
    "    \"godless entertainer\", \"Hollywood heathen\", \"celebrity atheist\", \"music industry satanist\", \n",
    "    \"anti-christian activist\", \"court god-hater\", \"judge atheist\", \"lawyer satanist\", \"anti-prayer warrior\", \n",
    "    \"school prayer hater\", \"public square atheist\", \"freedom from religion pusher\", \"godless bureaucrat\", \n",
    "    \"government atheist\", \"deep state atheist\", \"federal god-hater\", \"local government atheist\", \n",
    "    \"state government atheist\", \"media god-hater\", \"fake news atheist\", \"mainstream media satanist\", \n",
    "    \"liberal journalist\", \"godless reporter\", \"secular broadcaster\", \"anti-Christian media\", \n",
    "    \"abortion clinic worker\", \"Planned Parenthood supporter\", \"sex education pusher\", \"condom distributor\", \n",
    "    \"gay marriage supporter\", \"same-sex marriage advocate\", \"gender-neutral bathroom supporter\", \n",
    "    \"drag queen story hour promoter\", \"godless politician\", \"godless congressman\", \"secular senator\", \n",
    "    \"atheist president\", \"anti-Christian governor\", \"godless mayor\", \"godless city council member\", \n",
    "    \"leftist church leader\", \"liberal pastor\", \"godless bishop\", \"satanic preacher\", \"anti-christian reverend\"\n",
    "]\n",
    "\n",
    "anti_feminist_abusive_expressions = [\n",
    "    \"feminazi\", \"man-hater\", \"femscum\", \"gender terrorist\", \"militant feminist\", \"radical feminist\",\n",
    "    \"feminist whacko\", \"feminist nutjob\", \"feminist extremist\", \"men's rights hater\", \"women's libber\",\n",
    "    \"bra burner\", \"angry feminist\", \"toxic feminist\", \"feminist zealot\", \"feminist bigot\", \"feminist pig\",\n",
    "    \"man basher\", \"female supremacist\", \"misandrist\", \"gender bender\", \"liberal feminist\", \"intersectional feminist\",\n",
    "    \"third-wave feminist\", \"fourth-wave feminist\", \"feminist propagandist\", \"equality freak\", \"gender radical\",\n",
    "    \"female chauvinist\", \"gender equality extremist\", \"PC feminist\", \"progressive feminist\", \"women's lib extremist\",\n",
    "    \"women's rights radical\", \"feminist dictator\", \"gender justice warrior\", \"SJW feminist\", \"PC police feminist\",\n",
    "    \"feminist overlord\", \"man-hating feminist\", \"patriarchy smasher\", \"male basher\", \"anti-male feminist\",\n",
    "    \"male oppressor\", \"male privilege denier\", \"gender warrior\", \"sexist feminist\", \"gender equity freak\",\n",
    "    \"feminist hypocrite\", \"misandrist feminist\", \"women's rights fanatic\", \"gender revolutionist\", \"feminist agitator\",\n",
    "    \"feminist crusader\", \"feminist activist\", \"gender equity warrior\", \"feminist insurgent\", \"feminist troublemaker\",\n",
    "    \"feminist rabble-rouser\", \"feminist militant\", \"feminist extremist\", \"feminist terrorist\", \"gender radicalizer\",\n",
    "    \"gender equality zealot\", \"feminist ideologue\", \"feminist hardliner\", \"feminist fanatic\", \"feminist hardhead\",\n",
    "    \"feminist brainwasher\", \"gender equality dictator\", \"feminist regime supporter\", \"feminist dictator\",\n",
    "    \"feminist enforcer\", \"feminist totalitarian\", \"gender equality extremist\", \"feminist fundamentalist\",\n",
    "    \"feminist crusader\", \"feminist warrior\", \"feminist insurgent\", \"feminist zealot\", \"feminist authoritarian\",\n",
    "    \"feminist radicalizer\", \"gender equity extremist\", \"gender equality fanatic\", \"feminist autocrat\",\n",
    "    \"gender equity zealot\", \"feminist revolutionary\", \"feminist oppressor\", \"feminist autocrat\", \"feminist tyrant\",\n",
    "    \"gender equality tyrant\", \"feminist totalitarian\", \"feminist oppressor\", \"feminist enforcer\", \"feminist dictator\"\n",
    "]\n",
    "\n",
    "anti_lgbt_abusive_expressions = [\n",
    "    \"homophobe\", \"fag\", \"faggot\", \"dyke\", \"tranny\", \"queer\", \"sodomite\", \"pillow biter\",\n",
    "    \"rump ranger\", \"butt pirate\", \"queer bait\", \"nancy boy\", \"poofter\", \"fairy\", \"fruit\",\n",
    "    \"pansy\", \"lezzo\", \"he-she\", \"she-male\", \"gender bender\", \"fruitcake\", \"gaylord\",\n",
    "    \"homo\", \"carpet muncher\", \"muff diver\", \"lesbo\", \"fudge packer\", \"backdoor bandit\",\n",
    "    \"sissy\", \"nancy\", \"twink\", \"twinkie\", \"breeder\", \"gold star\", \"pillow queen\",\n",
    "    \"queen\", \"queen bee\", \"bent\", \"genderqueer\", \"genderfreak\", \"hermaphrodite\", \"invert\",\n",
    "    \"genderfuck\", \"genderless\", \"cis scum\", \"fruit loop\", \"rainbow warrior\", \"flamer\",\n",
    "    \"pillow biter\", \"pillow muncher\", \"rump wrangler\", \"bum bandit\", \"arse bandit\", \n",
    "    \"arse pirate\", \"cocksucker\", \"boy lover\", \"ball licker\", \"rainbow chaser\", \"lipstick lesbian\",\n",
    "    \"homo thug\", \"fruit bat\", \"fairy boy\", \"friend of Dorothy\", \"bugger\", \"gender terrorist\",\n",
    "    \"lesbian wannabe\", \"beard\", \"flit\", \"twinkie eater\", \"ladyboy\", \"genderqueer freak\",\n",
    "    \"pansexual\", \"genderfluid\", \"cisgender hater\", \"drag queen\", \"drag king\", \"cross-dresser\",\n",
    "    \"effeminate\", \"butch\", \"stone butch\", \"lipstick femme\", \"gender outlaws\", \"sexual deviant\",\n",
    "    \"sexually confused\", \"mentally ill\", \"unnatural\", \"deviant\", \"sinful\", \"abomination\",\n",
    "    \"pervert\", \"perverted\", \"predator\", \"recruiter\", \"child molester\", \"child abuser\"\n",
    "]\n",
    "\n",
    "combined_set = set(\n",
    "    swearing_words +\n",
    "    misogynistic_words +\n",
    "    incel_words +\n",
    "    race_abusive_words +\n",
    "    transgender_abusive_words +\n",
    "    muslim_abusive_words +\n",
    "    sexist_abusive_words +\n",
    "    abusive_lefties +\n",
    "    trumpists_abusive +\n",
    "    trumpist_abusive_expressions +\n",
    "    xenophobic_abusive_expressions +\n",
    "    trumpist_evangelical_abusive_expressions +\n",
    "    anti_feminist_abusive_expressions +\n",
    "    anti_lgbt_abusive_expressions\n",
    ")\n",
    "\n",
    "# Convert the set back to a list\n",
    "abusive_words = list(combined_set)\n",
    "print(len(abusive_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define templates for generating synthetic hate tweets\n",
    "templates = [\n",
    "    \"You are such a {word}, can't believe it!\",\n",
    "    \"Get lost, you {word}!\",\n",
    "    \"People like you are the worst, {word}!\",\n",
    "    \"No one likes a {word} like you!\",\n",
    "    \"Stay away, {word}!\",\n",
    "    \"You are the epitome of a {word}.\",\n",
    "    \"I can't stand {word}s like you.\",\n",
    "    \"Just go away, {word}.\",\n",
    "    \"You disgust me, {word}.\",\n",
    "    \"Only a {word} would say something like that.\",\n",
    "    \"You're nothing but a {word}.\",\n",
    "    \"What a {word} thing to do.\",\n",
    "    \"Shut up, {word}.\",\n",
    "    \"Nobody cares about a {word} like you.\",\n",
    "    \"You're such a {word}, seriously.\",\n",
    "    \"Get a life, {word}.\",\n",
    "    \"Why are you such a {word}?\",\n",
    "    \"I hate {word}s like you.\",\n",
    "    \"What kind of {word} are you?\",\n",
    "    \"You must be proud to be a {word}.\",\n",
    "    \"You {word}, stay away from me.\",\n",
    "    \"You're the worst kind of {word}.\",\n",
    "    \"It's people like you that give {word}s a bad name.\",\n",
    "    \"What a loser, {word}.\",\n",
    "    \"Go to hell, {word}.\",\n",
    "    \"You are nothing but a {word}.\",\n",
    "    \"Pathetic {word}.\",\n",
    "    \"Typical {word} behavior.\",\n",
    "    \"You make me sick, {word}.\",\n",
    "    \"You are the definition of a {word}.\",\n",
    "    \"How can you be such a {word}?\",\n",
    "    \"Just leave, {word}.\",\n",
    "    \"You're a joke, {word}.\",\n",
    "    \"Shame on you, {word}.\",\n",
    "    \"I can't believe you're a {word}.\",\n",
    "    \"Disgusting {word}.\",\n",
    "    \"You belong in the trash, {word}.\",\n",
    "    \"You are a total {word}.\",\n",
    "    \"Why would anyone want to be a {word} like you?\",\n",
    "    \"Nobody wants to hear from a {word}.\",\n",
    "    \"You're a disgrace, {word}.\",\n",
    "    \"Absolutely pathetic, {word}.\",\n",
    "    \"Why don't you just disappear, {word}?\",\n",
    "    \"You're the reason people hate {word}s.\",\n",
    "    \"You should be ashamed, {word}.\",\n",
    "    \"What a waste of space, {word}.\",\n",
    "    \"How can someone be so much of a {word}?\",\n",
    "    \"Do everyone a favor and shut up, {word}.\",\n",
    "    \"No one wants a {word} around.\",\n",
    "    \"You are absolutely worthless, {word}.\",\n",
    "    \"Nobody respects a {word} like you.\",\n",
    "    \"You're a waste, {word}.\",\n",
    "    \"You're pathetic, {word}.\",\n",
    "    \"You're a complete {word}.\",\n",
    "    \"You're a disgrace to {word}s everywhere.\",\n",
    "    \"Everyone hates a {word} like you.\",\n",
    "    \"You make the world a worse place, {word}.\",\n",
    "    \"You are the worst kind of {word}.\",\n",
    "    \"You should feel bad for being a {word}.\",\n",
    "    \"You're just another {word}.\",\n",
    "    \"Get out of here, {word}.\",\n",
    "    \"You're a terrible person, {word}.\",\n",
    "    \"Nobody likes a {word}.\",\n",
    "    \"You're the lowest of the low, {word}.\",\n",
    "    \"You're the worst, {word}.\",\n",
    "    \"You're a waste of breath, {word}.\",\n",
    "    \"You're just trash, {word}.\",\n",
    "    \"You're garbage, {word}.\",\n",
    "    \"You're nothing, {word}.\",\n",
    "    \"You're a nobody, {word}.\",\n",
    "    \"You're scum, {word}.\",\n",
    "    \"You're filth, {word}.\",\n",
    "    \"You're a piece of garbage, {word}.\",\n",
    "    \"You're a piece of trash, {word}.\",\n",
    "    \"You're worthless, {word}.\",\n",
    "    \"You're nothing but a {word}.\",\n",
    "    \"You're a waste of space, {word}.\",\n",
    "    \"You're a waste of time, {word}.\",\n",
    "    \"You're a waste of life, {word}.\",\n",
    "    \"You're a waste of air, {word}.\",\n",
    "    \"You're a waste of skin, {word}.\",\n",
    "    \"You're a waste of everything, {word}.\",\n",
    "    \"You're a waste, {word}.\",\n",
    "    \"You're useless, {word}.\",\n",
    "    \"You're a burden, {word}.\",\n",
    "    \"You're a disgrace, {word}.\",\n",
    "    \"You're a blight, {word}.\",\n",
    "    \"You're a stain, {word}.\",\n",
    "    \"You're a blemish, {word}.\",\n",
    "    \"You're an eyesore, {word}.\",\n",
    "    \"You're a blot, {word}.\",\n",
    "    \"You're a smudge, {word}.\",\n",
    "    \"You're a mark, {word}.\",\n",
    "    \"You're a scar, {word}.\",\n",
    "    \"You're a wound, {word}.\",\n",
    "    \"You're a lesion, {word}.\",\n",
    "    \"You're a disease, {word}.\",\n",
    "    \"You are a total {word}.\",\n",
    "    \"Why would anyone want to associate with a {word} like you?\",\n",
    "    \"You're a disgrace to humanity, {word}.\",\n",
    "    \"Every time you speak, you prove you're a {word}.\",\n",
    "    \"You're the lowest of the low, {word}.\",\n",
    "    \"I can't stand looking at a {word} like you.\",\n",
    "    \"You make everything worse, {word}.\",\n",
    "    \"Everyone hates a {word} like you.\",\n",
    "    \"The world would be better without {word}s like you.\",\n",
    "    \"You're nothing but a {word}.\",\n",
    "    \"Go crawl back into the hole you came from, {word}.\",\n",
    "    \"You should be ashamed of yourself, {word}.\",\n",
    "    \"What a joke, {word}.\",\n",
    "    \"You're a pathetic excuse for a human, {word}.\",\n",
    "    \"Nobody needs a {word} like you around.\",\n",
    "    \"You're a burden to society, {word}.\",\n",
    "    \"What a waste of life, {word}.\",\n",
    "    \"No one would miss you, {word}.\",\n",
    "    \"You're a stain on society, {word}.\",\n",
    "    \"You're an embarrassment, {word}.\",\n",
    "    \"People like you make me sick, {word}.\",\n",
    "    \"You're a waste of oxygen, {word}.\",\n",
    "    \"Why don't you just disappear, {word}?\",\n",
    "    \"You're a nuisance, {word}.\",\n",
    "    \"Nobody cares about your opinion, {word}.\",\n",
    "    \"You're irrelevant, {word}.\",\n",
    "    \"What a loser, {word}.\",\n",
    "    \"Go away, {word}.\",\n",
    "    \"You're an idiot, {word}.\",\n",
    "    \"You have no place here, {word}.\",\n",
    "    \"You're not welcome here, {word}.\",\n",
    "    \"What a disgrace, {word}.\",\n",
    "    \"You're an insult to humanity, {word}.\",\n",
    "    \"You make everything worse, {word}.\",\n",
    "    \"You're a joke, {word}.\",\n",
    "    \"You're pathetic, {word}.\",\n",
    "    \"You're worthless, {word}.\",\n",
    "    \"What a waste of space, {word}.\",\n",
    "    \"Nobody likes you, {word}.\",\n",
    "    \"You're a failure, {word}.\",\n",
    "    \"You're a nobody, {word}.\",\n",
    "    \"What a waste, {word}.\",\n",
    "    \"You're a blight on society, {word}.\",\n",
    "    \"You're a burden, {word}.\",\n",
    "    \"What a disgrace, {word}.\",\n",
    "    \"You're an eyesore, {word}.\",\n",
    "    \"You're a waste of time, {word}.\",\n",
    "    \"You're irrelevant, {word}.\",\n",
    "    \"Nobody needs you, {word}.\",\n",
    "    \"You're a pest, {word}.\",\n",
    "    \"You're an annoyance, {word}.\",\n",
    "    \"What a waste of air, {word}.\",\n",
    "    \"You're a disgrace to your family, {word}.\",\n",
    "    \"You're a disappointment, {word}.\",\n",
    "    \"Nobody respects you, {word}.\",\n",
    "    \"You're a joke to everyone, {word}.\",\n",
    "    \"Nobody likes a {word}.\",\n",
    "    \"What a pathetic {word}.\",\n",
    "    \"You're a disgrace to yourself, {word}.\",\n",
    "    \"You're a failure, {word}.\",\n",
    "    \"Nobody cares about a {word} like you.\",\n",
    "    \"You're a joke to society, {word}.\",\n",
    "    \"You're a loser, {word}.\",\n",
    "    \"You're a waste of life, {word}.\",\n",
    "    \"You're a waste of everything, {word}.\",\n",
    "    \"You're useless, {word}.\",\n",
    "    \"You're a waste of potential, {word}.\",\n",
    "    \"Nobody wants you around, {word}.\",\n",
    "    \"You're a burden to everyone, {word}.\",\n",
    "    \"You're a total waste, {word}.\",\n",
    "    \"You're an absolute failure, {word}.\",\n",
    "    \"You're a waste of talent, {word}.\",\n",
    "    \"Nobody wants to hear from a {word} like you.\",\n",
    "    \"You're a complete joke, {word}.\",\n",
    "    \"You're a waste of resources, {word}.\",\n",
    "    \"You're a waste of effort, {word}.\",\n",
    "    \"You're a waste of attention, {word}.\",\n",
    "    \"You're a waste of everything good, {word}.\",\n",
    "    \"You're a total embarrassment, {word}.\",\n",
    "    \"You're a disgrace to everything, {word}.\",\n",
    "    \"You're a total failure, {word}.\",\n",
    "    \"Nobody needs a {word} like you.\",\n",
    "    \"You're a complete waste, {word}.\",\n",
    "    \"You're a waste of everything valuable, {word}.\",\n",
    "    \"You're a waste of space and time, {word}.\",\n",
    "    \"You're a waste of good air, {word}.\",\n",
    "    \"You're a waste of energy, {word}.\",\n",
    "    \"You're a waste of existence, {word}.\",\n",
    "    \"You're a total waste of everything, {word}.\",\n",
    "    \"Nobody cares about a {word} like you.\",\n",
    "    \"You're a total waste of potential, {word}.\",\n",
    "    \"You're a total waste of life, {word}.\",\n",
    "    \"You're a waste of everyone's time, {word}.\",\n",
    "    \"You're a waste of everyone's effort, {word}.\",\n",
    "    \"You're a waste of everyone's attention, {word}.\",\n",
    "    \"You're a total waste of everyone's resources, {word}.\",\n",
    "    \"{word}, you are such a disgrace!\",\n",
    "    \"Can't believe it, {word}, you are the worst!\",\n",
    "    \"Stay away from me, {word}.\",\n",
    "    \"{word}, nobody likes you!\",\n",
    "    \"What a joke, {word}.\",\n",
    "    \"You {word}, must be proud to be a failure.\",\n",
    "    \"Only a {word} would say something like that.\",\n",
    "    \"Shut up, {word}, nobody cares about your opinion.\",\n",
    "    \"You're a joke, {word}.\",\n",
    "    \"{word}, you're a waste of space.\",\n",
    "    \"Get lost, {word}, you're pathetic.\",\n",
    "    \"Why don't you just disappear, {word}?\",\n",
    "    \"You are nothing but a {word}.\",\n",
    "    \"Pathetic {word}, just leave.\",\n",
    "    \"{word}, you're a complete joke.\",\n",
    "    \"What a loser, {word}.\",\n",
    "    \"{word}, you make me sick.\",\n",
    "    \"Disgusting {word}, stay away.\",\n",
    "    \"Absolutely pathetic, {word}.\",\n",
    "    \"You're the worst, {word}.\",\n",
    "    \"{word}, you're a disgrace.\",\n",
    "    \"Nobody wants a {word} around.\",\n",
    "    \"You should feel bad, {word}.\",\n",
    "    \"Go to hell, {word}.\",\n",
    "    \"You're worthless, {word}.\",\n",
    "    \"What kind of {word} are you?\",\n",
    "    \"{word}, you are absolutely worthless.\",\n",
    "    \"Do everyone a favor and shut up, {word}.\",\n",
    "    \"No one respects a {word} like you.\",\n",
    "    \"{word}, you're a waste of time.\",\n",
    "    \"You're just another {word}.\",\n",
    "    \"{word}, nobody needs you.\",\n",
    "    \"Get out of here, {word}.\",\n",
    "    \"You're a terrible person, {word}.\",\n",
    "    \"{word}, you're an idiot.\",\n",
    "    \"You have no place here, {word}.\",\n",
    "    \"What a disgrace, {word}.\",\n",
    "    \"{word}, you're an insult to humanity.\",\n",
    "    \"You make everything worse, {word}.\",\n",
    "    \"{word}, you're a joke.\",\n",
    "    \"What a waste, {word}.\",\n",
    "    \"You're a blight on society, {word}.\",\n",
    "    \"What a disgrace, {word}.\",\n",
    "    \"{word}, you're an eyesore.\",\n",
    "    \"You're a waste of air, {word}.\",\n",
    "    \"Nobody respects you, {word}.\",\n",
    "    \"{word}, you're a joke to everyone.\",\n",
    "    \"What a pathetic {word}.\",\n",
    "    \"You're a disgrace to yourself, {word}.\",\n",
    "    \"You're a failure, {word}.\",\n",
    "    \"{word}, you're a loser.\",\n",
    "    \"You're a waste of life, {word}.\",\n",
    "    \"{word}, you're a waste of everything.\",\n",
    "    \"You're useless, {word}.\",\n",
    "    \"Nobody wants you around, {word}.\",\n",
    "    \"You're a burden to everyone, {word}.\",\n",
    "    \"You're a total waste, {word}.\",\n",
    "    \"You're an absolute failure, {word}.\",\n",
    "    \"{word}, nobody wants to hear from you.\",\n",
    "    \"You're a waste of resources, {word}.\",\n",
    "    \"You're a waste of attention, {word}.\",\n",
    "    \"You're a total embarrassment, {word}.\",\n",
    "    \"{word}, you're a disgrace to everything.\"\n",
    "]\n",
    "\n",
    "# # Combine all the templates (if there are more)\n",
    "# all_templates = templates  # add more templates if you have\n",
    "\n",
    "# import random\n",
    "# # Function to generate synthetic hate tweets using the swearing words and templates\n",
    "# def generate_hate_tweets(swearing_words, templates, num_tweets=400):\n",
    "#     generated_tweets = []\n",
    "#     for _ in range(num_tweets):\n",
    "#         word = random.choice(swearing_words)\n",
    "#         template = random.choice(templates)\n",
    "#         tweet = template.format(word=word)\n",
    "#         generated_tweets.append(tweet)\n",
    "#     return generated_tweets\n",
    "\n",
    "# # Generate hate tweets using the swearing words and templates\n",
    "# generated_tweets = generate_hate_tweets(swearing_words, all_templates, num_tweets=1000)\n",
    "\n",
    "# # Create a dataframe for the generated tweets\n",
    "# generated_df = pd.DataFrame({\n",
    "#     'label': [1] * len(generated_tweets),\n",
    "#     'tweet': generated_tweets\n",
    "# })\n",
    "\n",
    "# # Display the generated hate tweets\n",
    "# print(generated_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              tweet\n",
      "0      1                      Disgusting sadism, stay away.\n",
      "1      1           You are absolutely worthless, tribadism.\n",
      "2      1              You belong in the trash, nymphomania.\n",
      "3      1                  What kind of nimphomania are you?\n",
      "4      1                  You're a waste of talent, raping.\n",
      "5      1                   Nobody needs a raghead like you.\n",
      "6      1                           You're a blemish, felch.\n",
      "7      1            You're a waste of space and time, dick.\n",
      "8      1         You're a waste of everything good, femdom.\n",
      "9      1  Every time you speak, you prove you're a date ...\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "import random\n",
    "import pandas as pd\n",
    "import spacy.cli\n",
    "\n",
    "# Ensure the SpaCy model is downloaded\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load SpaCy English tokenizer, POS tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to generate permutations of the template\n",
    "def permute_template(template, max_permutations=5):\n",
    "    placeholder = \"{word}\"\n",
    "    if placeholder not in template:\n",
    "        return []\n",
    "    \n",
    "    # Replace the placeholder with a temporary token for detection\n",
    "    doc = nlp(template.replace(placeholder, \"___\"))\n",
    "    word_index = [token.i for token in doc if token.text == \"___\"]\n",
    "    \n",
    "    if not word_index:\n",
    "        return []\n",
    "    \n",
    "    word_index = word_index[0]\n",
    "    \n",
    "    # Extract positions to insert the word\n",
    "    safe_positions = [i for i, token in enumerate(doc) if token.pos_ in {\"NOUN\", \"VERB\", \"ADJ\", \"ADV\", \"PUNCT\"}]\n",
    "    \n",
    "    # Generate permutations\n",
    "    permutations = []\n",
    "    for _ in range(max_permutations):\n",
    "        new_position = random.choice(safe_positions)\n",
    "        if new_position != word_index:  # Avoid the original position\n",
    "            tokens = [token.text for token in doc]\n",
    "            tokens.remove(\"___\")  # Remove the placeholder\n",
    "            tokens.insert(new_position, \"{word}\")\n",
    "            permutations.append(\" \".join(tokens))\n",
    "    return permutations\n",
    "\n",
    "# Define original templates\n",
    "templates = templates\n",
    "# Generate augmented templates\n",
    "augmented_templates = []\n",
    "for template in templates:\n",
    "    permutations = permute_template(template)\n",
    "    if permutations:\n",
    "        augmented_templates.extend(permutations)\n",
    "    else:\n",
    "        # If no permutations are generated, keep the original template\n",
    "        augmented_templates.append(template)\n",
    "\n",
    "# Remove duplicates if any\n",
    "augmented_templates = list(set(augmented_templates))\n",
    "\n",
    "# Check if augmented_templates is still empty\n",
    "if not augmented_templates:\n",
    "    raise ValueError(\"No augmented templates generated. Please check the permute_template function.\")\n",
    "\n",
    "# Function to generate synthetic hate tweets using the swearing words and templates\n",
    "def generate_hate_tweets(swearing_words, templates, num_tweets=400):\n",
    "    if not templates:\n",
    "        raise ValueError(\"Template list is empty. Cannot generate tweets.\")\n",
    "    \n",
    "    generated_tweets = []\n",
    "    for _ in range(num_tweets):\n",
    "        word = random.choice(swearing_words)\n",
    "        template = random.choice(templates)\n",
    "        tweet = template.format(word=word)\n",
    "        generated_tweets.append(tweet)\n",
    "    return generated_tweets\n",
    "\n",
    "# Sample swearing words (replace with actual swearing words)\n",
    "swearing_words = swearing_words\n",
    "\n",
    "# Generate hate tweets using the swearing words and augmented templates\n",
    "generated_tweets = generate_hate_tweets(swearing_words, augmented_templates, num_tweets=10000)\n",
    "\n",
    "# Create a dataframe for the generated tweets\n",
    "generated_df = pd.DataFrame({\n",
    "    'label': [1] * len(generated_tweets),\n",
    "    'tweet': generated_tweets\n",
    "})\n",
    "\n",
    "\n",
    "# Display the combined and shuffled DataFrame\n",
    "print(generated_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Duplicates based on 'tweet' column:\n",
      "      label                                            tweet\n",
      "13        1               You're an absolute failure, queaf.\n",
      "18        1                      mr hands, nobody likes you!\n",
      "29        1                               Get a life, bitch.\n",
      "30        1           figging, you are absolutely worthless.\n",
      "33        1              No one likes a doggystyle like you!\n",
      "...     ...                                              ...\n",
      "9962      1    You're a joke to everyone, cleveland steamer.\n",
      "9973      1                      footjob, you're a disgrace.\n",
      "9978      1                            You're nothing, suck.\n",
      "9988      1     You're a pathetic excuse for a human, coons.\n",
      "9996      1  Every time you speak, you prove you're a skeet.\n",
      "\n",
      "[1241 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(generated_df))\n",
    "\n",
    "duplicates = generated_df[generated_df.duplicated(subset='tweet', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "print(\"Duplicates based on 'tweet' column:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates based on 'tweet' column:\n",
      "0\n",
      "9369\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "generated_df = generated_df.drop_duplicates(subset='tweet')\n",
    "duplicates = generated_df[generated_df.duplicated(subset='tweet', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "print(\"Duplicates based on 'tweet' column:\")\n",
    "print(len(duplicates))\n",
    "print(len(generated_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>You're a complete penis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user singing makes me   ð¶ðð</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>You're a waste of resources, shaved pussy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>facce da set! ó¾´ #thereaping #thereapingthes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>You're a total waste of everything, lolita.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44745</th>\n",
       "      <td>0</td>\n",
       "      <td>@user how is this parking by one member of you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44746</th>\n",
       "      <td>1</td>\n",
       "      <td>What a loser, poop chute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44747</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#8220;@thekiddfranky: I talk to any girl who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44748</th>\n",
       "      <td>0</td>\n",
       "      <td>this makes me incredibly happy #oitnb #netflix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44749</th>\n",
       "      <td>1</td>\n",
       "      <td>No one would miss you, spread legs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "0          1                           You're a complete penis.\n",
       "1          0              @user singing makes me   ð¶ðð\n",
       "2          1         You're a waste of resources, shaved pussy.\n",
       "3          0  facce da set! ó¾´ #thereaping #thereapingthes...\n",
       "4          1        You're a total waste of everything, lolita.\n",
       "...      ...                                                ...\n",
       "44745      0  @user how is this parking by one member of you...\n",
       "44746      1                          What a loser, poop chute.\n",
       "44747      1  &#8220;@thekiddfranky: I talk to any girl who ...\n",
       "44748      0  this makes me incredibly happy #oitnb #netflix...\n",
       "44749      1                No one would miss you, spread legs.\n",
       "\n",
       "[44750 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([train_df_dirty, hate_2, generated_df],ignore_index=True)\n",
    "train_df_dirty = combined_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df_dirty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>You're a complete penis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user singing makes me   ð¶ðð</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>You're a waste of resources, shaved pussy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>facce da set! ó¾´ #thereaping #thereapingthes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>You're a total waste of everything, lolita.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44745</th>\n",
       "      <td>0</td>\n",
       "      <td>@user how is this parking by one member of you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44746</th>\n",
       "      <td>1</td>\n",
       "      <td>What a loser, poop chute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44747</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#8220;@thekiddfranky: I talk to any girl who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44748</th>\n",
       "      <td>0</td>\n",
       "      <td>this makes me incredibly happy #oitnb #netflix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44749</th>\n",
       "      <td>1</td>\n",
       "      <td>No one would miss you, spread legs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "id                                                             \n",
       "0          1                           You're a complete penis.\n",
       "1          0              @user singing makes me   ð¶ðð\n",
       "2          1         You're a waste of resources, shaved pussy.\n",
       "3          0  facce da set! ó¾´ #thereaping #thereapingthes...\n",
       "4          1        You're a total waste of everything, lolita.\n",
       "...      ...                                                ...\n",
       "44745      0  @user how is this parking by one member of you...\n",
       "44746      1                          What a loser, poop chute.\n",
       "44747      1  &#8220;@thekiddfranky: I talk to any girl who ...\n",
       "44748      0  this makes me incredibly happy #oitnb #netflix...\n",
       "44749      1                No one would miss you, spread legs.\n",
       "\n",
       "[44750 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_dirty.rename(columns={'index': 'id'}, inplace=True)\n",
    "train_df_dirty.index.name = 'id'\n",
    "train_df_dirty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates based on 'label' column:\n",
      "       label                                              tweet\n",
      "id                                                             \n",
      "6          1  ð @user  @user own team up with #new #mc @u...\n",
      "29         0  weddings are impoant because they celebrate li...\n",
      "42         0  #model   i love u take with u all the time in ...\n",
      "51         0   i am prepared. #i_am #positive #affirmation     \n",
      "59         0  can #lighttherapy help with   or #depression? ...\n",
      "...      ...                                                ...\n",
      "44665      0  looking to feel more #joy? join me and 20 spea...\n",
      "44666      0  #likescam   bull hill climb: you have to reach...\n",
      "44708      1  @user you might be a libtard if... #libtard  #...\n",
      "44715      0  i finally found a way how to delete old tweets...\n",
      "44729      0  find out about making schools   places @user @...\n",
      "\n",
      "[3126 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicates = train_df_dirty[train_df_dirty.duplicated(subset='tweet', keep=False)]\n",
    "\n",
    "# Display the duplicates\n",
    "print(\"Duplicates based on 'label' column:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after removing duplicates:\n",
      "42318\n"
     ]
    }
   ],
   "source": [
    "# If you want to remove duplicates based on the 'label' column\n",
    "train_df_dirty_no_duplicates = train_df_dirty.drop_duplicates(subset='tweet')\n",
    "\n",
    "# Display the DataFrame after removing duplicates\n",
    "print(\"DataFrame after removing duplicates:\")\n",
    "print(len(train_df_dirty_no_duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>You're a complete penis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user singing makes me   ð¶ðð</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>You're a waste of resources, shaved pussy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>facce da set! ó¾´ #thereaping #thereapingthes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>You're a total waste of everything, lolita.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44745</th>\n",
       "      <td>0</td>\n",
       "      <td>@user how is this parking by one member of you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44746</th>\n",
       "      <td>1</td>\n",
       "      <td>What a loser, poop chute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44747</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#8220;@thekiddfranky: I talk to any girl who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44748</th>\n",
       "      <td>0</td>\n",
       "      <td>this makes me incredibly happy #oitnb #netflix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44749</th>\n",
       "      <td>1</td>\n",
       "      <td>No one would miss you, spread legs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42318 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "id                                                             \n",
       "0          1                           You're a complete penis.\n",
       "1          0              @user singing makes me   ð¶ðð\n",
       "2          1         You're a waste of resources, shaved pussy.\n",
       "3          0  facce da set! ó¾´ #thereaping #thereapingthes...\n",
       "4          1        You're a total waste of everything, lolita.\n",
       "...      ...                                                ...\n",
       "44745      0  @user how is this parking by one member of you...\n",
       "44746      1                          What a loser, poop chute.\n",
       "44747      1  &#8220;@thekiddfranky: I talk to any girl who ...\n",
       "44748      0  this makes me incredibly happy #oitnb #netflix...\n",
       "44749      1                No one would miss you, spread legs.\n",
       "\n",
       "[42318 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_dirty_no_duplicates.to_csv('./DataSet/train_df_dirty.csv', index=True)\n",
    "train_df_dirty = pd.read_csv('./DataSet/train_df_dirty.csv', index_col='id')\n",
    "train_df_dirty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentated as above data set 'train_df_dirty' will be used for subsequent training. Since we use GPT-2 for tokanisation, data normalization and standardization for training a GPT model using Hugging Face's transformers library primarily involve ensuring the text is cleaned and properly tokenized. Since we will be using a tokenizer (GPT2Tokenizer), the primary preprocessing steps are to ensure the text is clean and ready for tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                              tweet\n",
      "id                                                             \n",
      "0          1                             youre a complete penis\n",
      "1          0                                   singing makes me\n",
      "2          1            youre a waste of resources shaved pussy\n",
      "3          0  facce da set thereaping thereapingtheseries co...\n",
      "4          1           youre a total waste of everything lolita\n",
      "...      ...                                                ...\n",
      "44745      0  how is this parking by one member of your staf...\n",
      "44746      1                            what a loser poop chute\n",
      "44747      1  i talk to any girl who paid over 300 for her s...\n",
      "44748      0  this makes me incredibly happy oitnb netflix l...\n",
      "44749      1                  no one would miss you spread legs\n",
      "\n",
      "[42318 rows x 2 columns]\n",
      "                                                   tweet\n",
      "id                                                      \n",
      "31963  studiolife aislife requires passion dedication...\n",
      "31964  white supremacists want everyone to see the ne...\n",
      "31965  safe ways to heal your acne altwaystoheal heal...\n",
      "31966  is the hp and the cursed child book up for res...\n",
      "31967  3rd bihday to my amazing hilarious nephew eli ...\n",
      "...                                                  ...\n",
      "49155  thought factory left-right polarisation trump ...\n",
      "49156  feeling like a mermaid hairflip neverready for...\n",
      "49157  hillary campaigned today in ohio((omg)) & used...\n",
      "49158  happy at work conference right mindset leads t...\n",
      "49159  my song \"so glad\" free download shoegaze newmu...\n",
      "\n",
      "[17197 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from Helpers.data_cleaner import TweetProcessor\n",
    "\n",
    "########################################## TRAIN ##################################################################\n",
    "# Ensure the text data does not contain any NaN values\n",
    "train_df_dirty['tweet'] = train_df_dirty['tweet'].fillna('')\n",
    "train_texts = train_df_dirty['tweet'].tolist()  # Your training texts\n",
    "train_labels = train_df_dirty['label'].tolist()  # Your training labels\n",
    "\n",
    "# Instantiate and use the TweetProcessor\n",
    "processor = TweetProcessor()\n",
    "columns_to_clean = ['tweet']  # Add other columns if needed\n",
    "cleaned_tweets_series_train = processor.process(train_df_dirty, columns=columns_to_clean)\n",
    "cleaned_tweets_txt_train = processor.process(train_df_dirty, columns=columns_to_clean, output_format='txt')\n",
    "cleaned_tweets_df_train = processor.process(train_df_dirty, columns=columns_to_clean, output_format='dataframe')\n",
    "\n",
    "# Display results\n",
    "#print(cleaned_tweets_series_train.head())\n",
    "#print(cleaned_tweets_txt_train[:500])  # Display first 500 characters of cleaned text\n",
    "print(cleaned_tweets_df_train)\n",
    "cleaned_tweets_df_train.to_csv()\n",
    "cleaned_tweets_df_train.to_csv('./DataSet/cleaned_tweets_train.csv')\n",
    "\n",
    "######################################## TEST #####################################################################\n",
    "# Ensure the text data does not contain any NaN values\n",
    "#test_df_dirty['tweet'] = test_df_dirty['tweet'].fillna('')\n",
    "test_texts = test_df_dirty['tweet'].tolist()  # Your training texts\n",
    "#test_labels = test_df_dirty['label'].tolist()  # Your training labels\n",
    "\n",
    "# Instantiate and use the TweetProcessor\n",
    "processor = TweetProcessor()\n",
    "columns_to_clean = ['tweet']  # Add other columns if needed\n",
    "cleaned_tweets_series_test = processor.process(test_df_dirty, columns=columns_to_clean)\n",
    "cleaned_tweets_txt_test = processor.process(test_df_dirty, columns=columns_to_clean, output_format='txt')\n",
    "cleaned_tweets_df_test = processor.process(test_df_dirty, columns=columns_to_clean, output_format='dataframe')\n",
    "\n",
    "# Display results\n",
    "#print(cleaned_tweets_series_test.head())\n",
    "#print(cleaned_tweets_txt_train[:500])  # Display first 500 characters of cleaned text\n",
    "print(cleaned_tweets_df_test)\n",
    "cleaned_tweets_df_train.to_csv()\n",
    "cleaned_tweets_df_train.to_csv('./DataSet/cleaned_tweets_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xl2",
   "language": "python",
   "name": "xl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
